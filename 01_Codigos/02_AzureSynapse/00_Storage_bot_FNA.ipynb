{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Crear tabla storage de PARCE\r\n",
        "\r\n",
        "Creación de la **tabla** de métricas relacionadas a las entradas o mensajes de usuarios, almacenados en nuestro contenedor de **Cosmo DB**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #1**: Importar los datos del contenedor de almacenamiento en *Cosmos DB*.\r\n",
        "\r\n",
        "* En *linea 6* se especifica el contenedor del cual se importan los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Write a Spark DataFrame into a Cosmos DB container\n",
        "\n",
        "df = spark.read\\\n",
        ".format(\"cosmos.oltp\")\\\n",
        ".option(\"spark.synapse.linkedService\", \"CosmosDb1\")\\\n",
        ".option(\"spark.cosmos.container\", \"bot-storage-FNA-v1\")\\\n",
        ".load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #2**: Seleccionar items del contenedor de Cosmos DB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Seleccionar campos de interés\r\n",
        "\r\n",
        "Data = df.select(\"document\",\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #3**: Construir la tabla principal del bot.\r\n",
        "\r\n",
        "El elemento **document** que seleccionamos en la celda anterior es una lista anidada, lurgo, se deben desplegar los elementos de dicha lista.\r\n",
        "\r\n",
        "Los elementos anidados en **document** son:\r\n",
        "\r\n",
        "* Entrada del usuario\r\n",
        "* Respuesta del bot\r\n",
        "* Fecha y hora\r\n",
        "* Indicador de entendimiento del bot (**S** = Bot respondió - **N** = Bot no entendió la pregunta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# 'Aplanar' columna principal\r\n",
        "\r\n",
        "Data1 = Data.rdd.map(lambda x: (x.id,x.document[\"turn_question\"],x.document[\"turn_answer\"],x.document[\"turn_date\"],x.document[\"turn_time\"],x.document[\"turn_understood\"]))\\\r\n",
        ".toDF([\"id\",\"turn_question\",\"turn_answer\",\"turn_date\",\"turn_time\",\"turn_understood\"])\r\n",
        "\r\n",
        "Data1 = Data1.withColumnRenamed(\"turn_question\",\"usuario\")\r\n",
        "Data1 = Data1.withColumnRenamed(\"turn_answer\",\"Respuesta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #4**: Importar el *diccionario* de servicio y etiquetas de las bases de conocimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Importar .csv para asociar Etiquetas y Servicios.\r\n",
        "\r\n",
        "Dicci = spark.read.load('abfss://bases@dlsfnaparce.dfs.core.windows.net/05_Diccionario.csv', format='csv'\r\n",
        ", header=True\r\n",
        ", delimiter='|'\r\n",
        ", encoding=\"ISO-8859-1\"\r\n",
        ")\r\n",
        "\r\n",
        "#--------------------\r\n",
        "from pyspark.sql.functions import regexp_replace\r\n",
        "Dicci = Dicci.withColumn('Respuesta', regexp_replace('Respuesta', \"_u_\",'\\n'))\r\n",
        "Dicci = Dicci.withColumn('Respuesta', regexp_replace('Respuesta', \"_\", ' '))\r\n",
        "#--------------------\r\n",
        "\r\n",
        "#print(Dicci.collect()[3]['Respuesta'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #5**: Adicionar métricas de *etiqueta* y *servicio* a la **tabla principal**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Tabla final\r\n",
        "\r\n",
        "Final = (Data1.join(Dicci, on = ['Respuesta'], how = 'left') )\r\n",
        "Final = Final[['id','usuario','Respuesta','turn_date','turn_time','turn_understood','Etiqueta','Servicio']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #6**: Renombrar indicador de entendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Configurar indicador understood y Etiqueta\r\n",
        "\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "Final = Final.withColumn('Etiqueta', when(Final.turn_understood == 'N', 'Default Bot').otherwise(Final.Etiqueta))\r\n",
        "Final = Final.withColumn('Servicio', when(Final.Etiqueta == 'Default Bot', 'Default Bot').otherwise(Final.Servicio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #7**: Renombrar intenciones de *Saludo* y acciones del *Chit-Chat*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Final = Final.withColumn('Etiqueta', when(Final.Etiqueta.isNull(), 'Saludo o ChitChat').otherwise(Final.Etiqueta))\r\n",
        "Final = Final.withColumn('Servicio', when(Final.Etiqueta == 'Saludo o ChitChat', 'Saludo o ChitChat').otherwise(Final.Servicio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #8**: Agregar *row_number*, para ejecución del *join* de Text Analytics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import row_number,lit\r\n",
        "from pyspark.sql.window import Window\r\n",
        "\r\n",
        "w = Window().orderBy(lit('A'))\r\n",
        "Final = Final.withColumn(\"row\", row_number().over(w)-1)\r\n",
        "\r\n",
        "Final = Final[['row','id','usuario','Respuesta','turn_date','turn_time','turn_understood','Etiqueta','Servicio']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #9**: Visualización de la tabla, parcial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# Final.printSchema()\r\n",
        "display(Final)\r\n",
        "\r\n",
        "# Final.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Análisis de texto con *Text Analytics*\r\n",
        "\r\n",
        "En esta sección, se usa el servicio de **Text Analytics** de Azure, para hacer análisis de texto de la entrada del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Analísis de texto\r\n",
        "\r\n",
        "Con el servicio de **Text Analytics** de *Azure* se pretenden enriquecer la tabla de información del chatbot, esta herramienta permite obtener métricas de **sentimientos** de la entrada del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #1**: Conectarse a **text_analytics_client** con las credenciales correspondentes del servicio desplegado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from azure.core.credentials import AzureKeyCredential\r\n",
        "from azure.ai.textanalytics import (\r\n",
        "    TextAnalyticsClient,\r\n",
        "    RecognizeEntitiesAction,\r\n",
        "    AnalyzeSentimentAction,\r\n",
        ")\r\n",
        "\r\n",
        "credential = AzureKeyCredential(\"505c3ba3a57a4b749a5e5a96a589d39a\")\r\n",
        "endpoint=\"https://eastus2.api.cognitive.microsoft.com/\"\r\n",
        "\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint, credential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #2**: La columna de interés es **Final.usuario** que corresponde a la entrada del usuario, luego, se procede como sigue:\r\n",
        "\r\n",
        "1. Convertir **Final.usuario** en lista.\r\n",
        "2. Pasar la lista anterior a la herramienta de *Text Analytics*, con: 1. Análisis de sentimientos y 2. Frases claves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#--- Convertir df.usuario a lista\r\n",
        "documents = list(Final.select('usuario').toPandas()['usuario'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #3**: Crear una lista de n-tuplas, donde cada tupla relaciona el id posicional de la lista de entradas con sus respectivas métricas de sentimiento, y luego, reestructurarlo en un dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#------- Análisis de sentimientos\r\n",
        "response = text_analytics_client.analyze_sentiment(documents, language=\"es\")\r\n",
        "result = [doc for doc in response if not doc.is_error]\r\n",
        "\r\n",
        "n = list()\r\n",
        "\r\n",
        "for doc in result:\r\n",
        "    k = (doc.id\r\n",
        "         ,doc.sentiment\r\n",
        "         ,doc.confidence_scores.positive\r\n",
        "         ,doc.confidence_scores.neutral\r\n",
        "         ,doc.confidence_scores.negative)\r\n",
        "    n.append(k)\r\n",
        "\r\n",
        "#print(n)\r\n",
        "\r\n",
        "#-- Crear DF\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType, FloatType\r\n",
        "\r\n",
        "# Create a schema for the dataframe\r\n",
        "schema = StructType([\r\n",
        "    StructField('Id', StringType(), True),\r\n",
        "    StructField('sentimiento', StringType(), True),\r\n",
        "    StructField('score_positivo', FloatType(), True),\r\n",
        "    StructField('score_neutral', FloatType(), True),\r\n",
        "    StructField('score_negativo', FloatType(), True)\r\n",
        "])\r\n",
        "\r\n",
        "# Convert list to RDD\r\n",
        "rdd = spark.sparkContext.parallelize(n)\r\n",
        "\r\n",
        "# Create data frame\r\n",
        "df01 = spark.createDataFrame(rdd,schema)\r\n",
        "# print(df.schema)\r\n",
        "df01 = df01.withColumnRenamed(\"Id\",\"row\")\r\n",
        "df01.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#------- Detector de frases clave\r\n",
        "response = text_analytics_client.extract_key_phrases(documents, language=\"es\")\r\n",
        "result = [doc for doc in response if not doc.is_error]\r\n",
        "\r\n",
        "n = list()\r\n",
        "\r\n",
        "for doc in result:\r\n",
        "    k = (doc.id\r\n",
        "         ,doc.key_phrases)\r\n",
        "    n.append(k)\r\n",
        "\r\n",
        "#print(n)\r\n",
        "\r\n",
        "#-- Crear DF\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType, FloatType\r\n",
        "\r\n",
        "# Create a schema for the dataframe\r\n",
        "schema = StructType([\r\n",
        "    StructField('Id', StringType(), True),\r\n",
        "    StructField('frase_clave', StringType(), True)\r\n",
        "])\r\n",
        "\r\n",
        "# Convert list to RDD\r\n",
        "rdd = spark.sparkContext.parallelize(n)\r\n",
        "\r\n",
        "# Create data frame\r\n",
        "df02 = spark.createDataFrame(rdd,schema)\r\n",
        "# print(df.schema)\r\n",
        "df02 = df02.withColumnRenamed(\"Id\",\"row\")\r\n",
        "df02.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #4**: Join de los dataframe de nuevas métricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# Join de métricas nuevas\r\n",
        "\r\n",
        "inter = (df01.join(df02, on = ['row'], how = 'left') )\r\n",
        "#inter.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #5**: Relacionar con *join* el df Final con el df de métricas de sentimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# Tabla parcial de sentimientos\r\n",
        "\r\n",
        "View = (Final.join(inter, on = ['row'], how = 'inner') )\r\n",
        "display(View)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "View.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Predicción de intenciones con LUIS\r\n",
        "\r\n",
        "En esta sección, con la app **LUIS** de Azure en SDK, se crean 2 nuevas columnas:\r\n",
        "* **appLUIS**: Prediccion de intención de LUIS de la columna *usuario*.\r\n",
        "* **scoreLUIS**: Score de la predicción de LUIS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #1**: Importación de librerias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from azure.cognitiveservices.language.luis.runtime import LUISRuntimeClient\r\n",
        "from msrest.authentication import CognitiveServicesCredentials\r\n",
        "from azure.cognitiveservices.language.luis.authoring import LUISAuthoringClient\r\n",
        "from azure.cognitiveservices.language.luis.authoring.models import ApplicationCreateObject\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from types import SimpleNamespace\r\n",
        "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType, FloatType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #2**: Configuración de credenciales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#----------- Credenciales\r\n",
        "authoringKey = 'ad5103875f974213af5db4ca3d997460'\r\n",
        "authoringEndpoint = 'https://cog-luis-fna-parce-authoring.cognitiveservices.azure.com/'\r\n",
        "\r\n",
        "app_id = \"7e20d5a3-2949-449d-b550-0f2e66ddaa40\"\r\n",
        "predictionKey = 'bc07e0dc5d25489091aad03387caf06a'\r\n",
        "predictionEndpoint = 'https://EastUS2.api.cognitive.microsoft.com/'\r\n",
        "\r\n",
        "#----------- Client\r\n",
        "client = LUISAuthoringClient(authoringEndpoint, CognitiveServicesCredentials(authoringKey))\r\n",
        "\r\n",
        "#----------- Client runtime\r\n",
        "runtimeCredentials = CognitiveServicesCredentials(predictionKey)\r\n",
        "clientRuntime = LUISRuntimeClient(endpoint=predictionEndpoint, credentials=runtimeCredentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #3**: Creación de función de consulta a la appLUIS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def LUIS(x):\r\n",
        "    x = str(x)\r\n",
        "\r\n",
        "    #----------- Configuración del REST CALL\r\n",
        "    headers = {}\r\n",
        "    params ={'query': x, 'subscription-key': predictionKey}\r\n",
        "\r\n",
        "    # Make the REST call.\r\n",
        "    response = requests.get(f'{predictionEndpoint}luis/prediction/v3.0/apps/{app_id}/slots/production/predict'\r\n",
        "                            , headers=headers\r\n",
        "                            , params=params)\r\n",
        "    \r\n",
        "    from types import SimpleNamespace    \r\n",
        "    a = response.json()\r\n",
        "    m = SimpleNamespace(**a)\r\n",
        "\r\n",
        "    b = m.prediction\r\n",
        "    n = SimpleNamespace(**b)\r\n",
        "\r\n",
        "    c = n.intents\r\n",
        "    o = SimpleNamespace(**c)\r\n",
        "\r\n",
        "    k = list(c.values())\r\n",
        "    p = k[0]\r\n",
        "    q = SimpleNamespace(**p)\r\n",
        "    \r\n",
        "    #, q.score\r\n",
        "    return str(n.topIntent)+'-'+str(q.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #4**: Convertir la función anterior a **UDF**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Convert a Python function to PySpark UDF\r\n",
        "\r\n",
        "from pyspark.sql.functions import udf, col\r\n",
        "\r\n",
        "\"\"\" Converting function to UDF \"\"\"\r\n",
        "LUIS_UDF = udf(lambda z: LUIS(z),StringType())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #5**: Aplicar la función UDF a la columna View.usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Aplicar la funcion UDF de LUIS a la columna de usuario\r\n",
        "View = Final.withColumn(\"LUIS\", LUIS_UDF(col(\"usuario\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #6**: Split de la nueva columna *LUIS*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import pyspark\r\n",
        "\r\n",
        "# Split de la columna LUIS\r\n",
        "split_cols = pyspark.sql.functions.split(View['LUIS'], '-')\r\n",
        "  \r\n",
        "# Aplicar split con '-'\r\n",
        "View = View.withColumn('appLUIS', split_cols.getItem(0)).withColumn('LUIS_score', split_cols.getItem(1))\r\n",
        "\r\n",
        "# Eliminar col LUIS\r\n",
        "View = View.drop('LUIS')\r\n",
        "\r\n",
        "# Ajustar tipo de col en score\r\n",
        "View = View.withColumn(\"LUIS_score\", View[\"LUIS_score\"].cast(FloatType()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Visualizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "display(View)\r\n",
        "View.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Guardar la tabla\r\n",
        "En esta sección se ejecutan los pasos para **guardar** la tabla creada en las secciones anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #1**: Crear la tabla *Final*. Se ejecutan una única vez (*Crear el if condicional para que no haya error al volver a ejecutar*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# \r\n",
        "View.createOrReplaceTempView(\"Final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        },
        "collapsed": true
      },
      "source": [
        "%%spark\r\n",
        "val scala_df = spark.sqlContext.sql(\"SELECT * FROM Final\")\r\n",
        "scala_df.write.synapsesql(\"syndwfnaparce.dbo.Final\", Constants.INTERNAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #2**: Conexión con el servicio de datalake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.conf.set(\r\n",
        "  \"fs.azure.account.key.dlsfnaparce.blob.core.windows.net\",\r\n",
        "  \"1y5feFvWNy6C4YGZlGlR/9wEwLeG51EDyGqsgkOiOLW2AndQmnj4PE7Ri+TgRJIC0Mghu5Z4KgqwjdQHZEhE0w==\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #3**: Relacionamos un **contenedor** (*test*) para crear la carpeta *'storage_bot'*, donde se guarda la información con la extención **.parquet**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "target_folder_path = 'abfss://test@dlsfnaparce.dfs.core.windows.net/storage_bot/'\r\n",
        "\r\n",
        "View.write.format(\"parquet\").mode(\"overwrite\").save(target_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Celda #4**: Ingresar a la ruta definida anteriormente, y visualizar lo que se ha guardado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "df_datos = spark.read.load('abfss://test@dlsfnaparce.dfs.core.windows.net/storage_bot/*.parquet', format='parquet')\r\n",
        "display(df_datos)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}